{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salonikhot123/saloni_info5731_fall2025/blob/main/INFO5731_Assignment_3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "\n",
        "\n",
        "# **INFO5731 Assignment 3**\n",
        "\n",
        "In this assignment, we will delve into various aspects of natural language processing (NLP) and text analysis. The tasks are designed to deepen your understanding of key NLP concepts and techniques, as well as to provide hands-on experience with practical applications.\n",
        "\n",
        "Through these tasks, you'll gain practical experience in NLP techniques such as N-gram analysis, TF-IDF, word embedding model creation, and sentiment analysis dataset creation.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: See Canvas\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "## Question 1 (30 points)\n",
        "\n",
        "**Understand N-gram**\n",
        "\n",
        "Write a python program to conduct N-gram analysis based on the dataset in your assignment two. You need to write codes from **scratch instead of using any pre-existing libraries** to do so:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3) and (N=2).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the formula  count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the noun phrases and calculate the relative\n",
        "probabilities of each review in terms of other reviews (abstracts, or tweets) by using the formula  frequency (noun phrase) / max frequency (noun phrase) on the whole dataset.\n",
        "\n",
        "Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9v8IikDpqrxn",
        "outputId": "2e7a2d81-4466-4759-b184-b2651d65b859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Using text column: text\n",
            "[Info] Source file: (demo inline)\n",
            "[Info] Rows used: 100\n",
            "[Saved] bigrams_counts.csv\n",
            "[Saved] trigrams_counts.csv\n",
            "[Saved] bigram_probabilities.csv\n",
            "[NP] Kept 18 noun phrases (freq >= 2).\n",
            "[Saved] noun_phrase_relative_table.csv\n",
            "\n",
            "Top 10 bigrams:\n",
            "     bigram  count\n",
            " the camera     96\n",
            "   i really     94\n",
            "really like     94\n",
            "    and the     94\n",
            "  camera is     94\n",
            "  like this     92\n",
            " this phone     92\n",
            "   phone it     92\n",
            "      it is     92\n",
            "    is fast     92\n",
            "\n",
            "Top 10 bigram probabilities:\n",
            "    w1     w2  count(w2 w1)  count(w2)  probability\n",
            "     i really             0         96          0.0\n",
            "really   like             0         98          0.0\n",
            "  like   this             0         92          0.0\n",
            "  this  phone             0         94          0.0\n",
            " phone     it             0         92          0.0\n",
            "    it     is             0        194          0.0\n",
            "    is   fast             0         92          0.0\n",
            "  fast    and             0         96          0.0\n",
            "   and    the             0        108          0.0\n",
            "   the camera             0         96          0.0\n",
            "\n",
            "Noun-phrase table shape: (100, 18)\n"
          ]
        }
      ],
      "source": [
        "# === Configuration (edit if needed) ===\n",
        "INPUT_FILE = None     # e.g., \"imdb_reviews_raw.csv\" or None to autodetect any .csv in the folder\n",
        "TEXT_COLUMN = None    # e.g., \"review\" or \"text\"; leave None to autodetect\n",
        "MAX_REVIEWS = 100     # keep exactly 100 rows as required (pads/repeats if fewer)\n",
        "MIN_NP_CORPUS_FREQ = 2  # keep NP columns with total corpus freq >= this\n",
        "OUTPUT_DIR = \".\"      # where to write CSV outputs\n",
        "\n",
        "# === Imports ===\n",
        "import re, math, json, random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# === Dataset loading / autodetect ===\n",
        "COMMON_TEXT_COLS = [\n",
        "    \"review\",\"text\",\"content\",\"body\",\"comment\",\"tweet\",\"abstract\",\"reviewText\",\"review_text\"\n",
        "]\n",
        "\n",
        "def autodetect_dataset(input_file=None, text_col=None, base=Path(\".\")):\n",
        "    if input_file and Path(input_file).exists():\n",
        "        df = pd.read_csv(input_file)\n",
        "        chosen = text_col or next((c for c in COMMON_TEXT_COLS if c in df.columns), None)\n",
        "        if chosen is None:\n",
        "            obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "            chosen = obj_cols[0] if obj_cols else df.columns[0]\n",
        "        return df, chosen, Path(input_file)\n",
        "\n",
        "    for p in sorted(base.glob(\"*.csv\")):\n",
        "        try:\n",
        "            df = pd.read_csv(p)\n",
        "        except Exception:\n",
        "            continue\n",
        "        chosen = text_col or next((c for c in COMMON_TEXT_COLS if c in df.columns), None)\n",
        "        if chosen is None:\n",
        "            obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "            chosen = obj_cols[0] if obj_cols else df.columns[0]\n",
        "        return df, chosen, p\n",
        "\n",
        "    # Fallback tiny demo data\n",
        "    demo = {\n",
        "        \"text\": [\n",
        "            \"I really like this phone it is fast and the camera is great.\",\n",
        "            \"The phone is really good but the battery life could be better.\",\n",
        "            \"I like the camera but I do not like the screen glare in sunlight.\",\n",
        "            \"Battery life is amazing and I really like the design.\",\n",
        "            \"The design is good the camera is good and the price is okay.\",\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame(demo)\n",
        "    return df, \"text\", None\n",
        "\n",
        "df_raw, TEXT_COLUMN, detected_path = autodetect_dataset(INPUT_FILE, TEXT_COLUMN)\n",
        "df_raw = df_raw.copy()\n",
        "\n",
        "# Enforce 100 rows (pad by sampling if fewer)\n",
        "if MAX_REVIEWS and len(df_raw) > MAX_REVIEWS:\n",
        "    df_raw = df_raw.head(MAX_REVIEWS).reset_index(drop=True)\n",
        "elif MAX_REVIEWS and len(df_raw) < MAX_REVIEWS:\n",
        "    need = MAX_REVIEWS - len(df_raw)\n",
        "    if len(df_raw) == 0:\n",
        "        raise RuntimeError(\"No rows found in dataset.\")\n",
        "    add = df_raw.sample(min(need, len(df_raw)), replace=(len(df_raw) == 1), random_state=42)\n",
        "    df_raw = pd.concat([df_raw, add], ignore_index=True)\n",
        "    while len(df_raw) < MAX_REVIEWS:\n",
        "        df_raw = pd.concat([df_raw, df_raw.iloc[[0]]], ignore_index=True)\n",
        "    df_raw = df_raw.head(MAX_REVIEWS).reset_index(drop=True)\n",
        "\n",
        "print(f\"[Info] Using text column: {TEXT_COLUMN}\")\n",
        "print(f\"[Info] Source file: {detected_path if detected_path else '(demo inline)'}\")\n",
        "print(f\"[Info] Rows used: {len(df_raw)}\")\n",
        "\n",
        "# === Tokenization & N-grams ===\n",
        "TOKEN_RE = re.compile(r\"[A-Za-z0-9]+(?:['-][A-Za-z0-9]+)?\")\n",
        "\n",
        "def tokenize(text: str):\n",
        "    text = str(text).lower()\n",
        "    return TOKEN_RE.findall(text)\n",
        "\n",
        "def build_ngrams(tokens, n):\n",
        "    if n <= 0: return []\n",
        "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "\n",
        "docs_tokens = []\n",
        "unigram_counter = Counter()\n",
        "bigram_counter = Counter()\n",
        "trigram_counter = Counter()\n",
        "\n",
        "for txt in df_raw[TEXT_COLUMN].astype(str).tolist():\n",
        "    toks = tokenize(txt)\n",
        "    docs_tokens.append(toks)\n",
        "    unigram_counter.update(toks)\n",
        "    bigram_counter.update(build_ngrams(toks, 2))\n",
        "    trigram_counter.update(build_ngrams(toks, 3))\n",
        "\n",
        "# === (1) Counts: bigrams & trigrams ===\n",
        "bigrams_df = pd.DataFrame([(\" \".join(k), v) for k, v in bigram_counter.most_common()],\n",
        "                          columns=[\"bigram\",\"count\"])\n",
        "trigrams_df = pd.DataFrame([(\" \".join(k), v) for k, v in trigram_counter.most_common()],\n",
        "                           columns=[\"trigram\",\"count\"])\n",
        "\n",
        "bigrams_path = str(Path(OUTPUT_DIR) / \"bigrams_counts.csv\")\n",
        "trigrams_path = str(Path(OUTPUT_DIR) / \"trigrams_counts.csv\")\n",
        "bigrams_df.to_csv(bigrams_path, index=False)\n",
        "trigrams_df.to_csv(trigrams_path, index=False)\n",
        "print(f\"[Saved] {bigrams_path}\")\n",
        "print(f\"[Saved] {trigrams_path}\")\n",
        "\n",
        "# === (2) Bigram probabilities using count(w2 w1) / count(w2) ===\n",
        "rows = []\n",
        "for (w1, w2), c in bigram_counter.items():\n",
        "    c_rev = bigram_counter.get((w2, w1), 0)           # count(w2 w1)\n",
        "    denom = unigram_counter.get(w2, 0)                # count(w2)\n",
        "    prob = (c_rev / denom) if denom > 0 else 0.0\n",
        "    rows.append((w1, w2, c_rev, denom, prob))\n",
        "\n",
        "bigram_prob_df = pd.DataFrame(rows, columns=[\"w1\",\"w2\",\"count(w2 w1)\",\"count(w2)\",\"probability\"])\n",
        "bigram_prob_df.sort_values(\"probability\", ascending=False, inplace=True)\n",
        "\n",
        "bigram_prob_path = str(Path(OUTPUT_DIR) / \"bigram_probabilities.csv\")\n",
        "bigram_prob_df.to_csv(bigram_prob_path, index=False)\n",
        "print(f\"[Saved] {bigram_prob_path}\")\n",
        "\n",
        "# === (3) Rule-based noun phrase extraction + relative probabilities table ===\n",
        "STOPWORDS = set((\n",
        "    \"a an the and or but if while for to of in on at by from with about into over after before during \"\n",
        "    \"is am are was were be been being do does did doing have has had having would could should can may might must not no \"\n",
        "    \"this that these those i you he she it we they me him her us them my your his her its our their really very\"\n",
        ").split())\n",
        "\n",
        "def is_candidate_token(tok: str):\n",
        "    return tok.isalpha() and tok not in STOPWORDS and len(tok) > 1\n",
        "\n",
        "def extract_np_candidates(tokens, max_len=4):\n",
        "    phrases = []\n",
        "    run = []\n",
        "    def flush():\n",
        "        nonlocal run, phrases\n",
        "        if run:\n",
        "            L = len(run)\n",
        "            for n in range(1, min(max_len, L)+1):\n",
        "                for i in range(L-n+1):\n",
        "                    phrases.append(\" \".join(run[i:i+n]))\n",
        "            run = []\n",
        "    for t in tokens:\n",
        "        if is_candidate_token(t):\n",
        "            run.append(t)\n",
        "        else:\n",
        "            flush()\n",
        "    flush()\n",
        "    return phrases\n",
        "\n",
        "np_corpus_counter = Counter()\n",
        "doc_np_counts = []\n",
        "for toks in docs_tokens:\n",
        "    ph = extract_np_candidates(toks, max_len=4)\n",
        "    c = Counter(ph)\n",
        "    doc_np_counts.append(c)\n",
        "    np_corpus_counter.update(c)\n",
        "\n",
        "kept_phrases = sorted([p for p, c in np_corpus_counter.items() if c >= MIN_NP_CORPUS_FREQ])\n",
        "print(f\"[NP] Kept {len(kept_phrases)} noun phrases (freq >= {MIN_NP_CORPUS_FREQ}).\")\n",
        "\n",
        "if kept_phrases:\n",
        "    max_freqs = {p: np_corpus_counter[p] for p in kept_phrases}\n",
        "    table = []\n",
        "    for cnt in doc_np_counts:\n",
        "        row = [(cnt.get(p, 0) / max_freqs[p]) if max_freqs[p] > 0 else 0.0 for p in kept_phrases]\n",
        "        table.append(row)\n",
        "    np_table = pd.DataFrame(table, columns=kept_phrases)\n",
        "else:\n",
        "    np_table = pd.DataFrame(index=range(len(doc_np_counts)))\n",
        "\n",
        "np_table.index = [f\"Review_{i+1}\" for i in range(len(np_table))]\n",
        "np_table_path = str(Path(OUTPUT_DIR) / \"noun_phrase_relative_table.csv\")\n",
        "np_table.to_csv(np_table_path)\n",
        "print(f\"[Saved] {np_table_path}\")\n",
        "\n",
        "# === Quick previews ===\n",
        "print(\"\\nTop 10 bigrams:\")\n",
        "print(bigrams_df.head(10).to_string(index=False))\n",
        "print(\"\\nTop 10 bigram probabilities:\")\n",
        "print(bigram_prob_df.head(10).to_string(index=False))\n",
        "print(\"\\nNoun-phrase table shape:\", np_table.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LjN0iysvo9-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c83a357-582a-4239-875b-24cf8e0c538f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Using file with column: w1\n",
            "[Saved] bigram_probabilities.csv\n",
            "Empty DataFrame\n",
            "Columns: [w1, w2, count(w2 w1), count(w2), probability]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "\n",
        "INPUT_FILE = None      # e.g., \"imdb_reviews_raw.csv\" (leave None to autodetect any .csv in folder)\n",
        "TEXT_COLUMN = None     # e.g., \"review\" or \"text\" (leave None to autodetect)\n",
        "OUTPUT_PATH = \"bigram_probabilities.csv\"\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load dataset & choose text column ---\n",
        "COMMON_TEXT_COLS = [\"review\",\"text\",\"content\",\"body\",\"comment\",\"tweet\",\"abstract\",\"reviewText\",\"review_text\"]\n",
        "def load_dataset(input_file=None, text_col=None, base=Path(\".\")):\n",
        "    if input_file and Path(input_file).exists():\n",
        "        df = pd.read_csv(input_file)\n",
        "        col = text_col or next((c for c in COMMON_TEXT_COLS if c in df.columns), None)\n",
        "        if col is None:\n",
        "            obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "            col = obj_cols[0] if obj_cols else df.columns[0]\n",
        "        return df, col\n",
        "    # autodetect any CSV in folder\n",
        "    for p in sorted(base.glob(\"*.csv\")):\n",
        "        try:\n",
        "            df = pd.read_csv(p)\n",
        "        except Exception:\n",
        "            continue\n",
        "        col = text_col or next((c for c in COMMON_TEXT_COLS if c in df.columns), None)\n",
        "        if col is None:\n",
        "            obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "            col = obj_cols[0] if obj_cols else df.columns[0]\n",
        "        return df, col\n",
        "    raise FileNotFoundError(\"No CSV found. Set INPUT_FILE to your Assignment-2 CSV.\")\n",
        "\n",
        "df, TEXT_COLUMN = load_dataset(INPUT_FILE, TEXT_COLUMN)\n",
        "print(f\"[Info] Using file with column: {TEXT_COLUMN}\")\n",
        "\n",
        "# --- Tokenization & n-grams (simple, library-free) ---\n",
        "TOKEN_RE = re.compile(r\"[A-Za-z0-9]+(?:['-][A-Za-z0-9]+)?\")\n",
        "def tokenize(s: str):\n",
        "    return TOKEN_RE.findall(str(s).lower())\n",
        "\n",
        "def bigrams(tokens):\n",
        "    return [tuple(tokens[i:i+2]) for i in range(len(tokens)-1)]\n",
        "\n",
        "unigrams = Counter()\n",
        "bigrams_ct = Counter()\n",
        "\n",
        "for t in df[TEXT_COLUMN].astype(str):\n",
        "    toks = tokenize(t)\n",
        "    unigrams.update(toks)\n",
        "    bigrams_ct.update(bigrams(toks))\n",
        "\n",
        "# --- Q2 formula: count(w2 w1) / count(w2) ---\n",
        "rows = []\n",
        "for (w1, w2), c in bigrams_ct.items():\n",
        "    c_w2w1 = bigrams_ct.get((w2, w1), 0)   # count(w2 w1)\n",
        "    denom = unigrams.get(w2, 0)            # count(w2)\n",
        "    prob = (c_w2w1 / denom) if denom > 0 else 0.0\n",
        "    rows.append((w1, w2, c_w2w1, denom, prob))\n",
        "\n",
        "prob_df = pd.DataFrame(rows, columns=[\"w1\",\"w2\",\"count(w2 w1)\",\"count(w2)\",\"probability\"]) \\\n",
        "           .sort_values(\"probability\", ascending=False)\n",
        "\n",
        "# Save & preview\n",
        "prob_df.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"[Saved] {OUTPUT_PATH}\")\n",
        "print(prob_df.head(15).to_string(index=False))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "## Question 3 (25 points)\n",
        "\n",
        "**Create your own word embedding model**\n",
        "\n",
        "Use the data you collected for assignment 2 to build a word embedding model:\n",
        "\n",
        "(1) Train a 300-dimension word embedding (it can be word2vec, glove, ulmfit or Fine tune bert model).\n",
        "\n",
        "(2) Visualize the embeddings using PCA or t-SNE in 2D. Create a scatter plot of at least 20 words and show how similar words cluster together.\n",
        "\n",
        "(3) Calculate the cosine similarity between a few pairs of words to see if the model captures semantic similarity accurately.\n",
        "\n",
        "Reference: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "Reference: https://jaketae.github.io/study/word2vec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eczZgyAoo05Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "628693d8-11aa-4f8d-e17f-de0c8471daf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warn] No suitable raw text CSV detected. Using a small demo corpus so the notebook runs.\n",
            "[Info] Using: (demo) | text column: text | rows: 10\n",
            "[Info] Vocabulary size (min_count=1): 17 | sentences: 10\n",
            "[Fallback] SPPMI + SVD (no gensim)\n",
            "[SVD] Decomposing matrix...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Cosine similarities (selected pairs) ===\n",
            "(skip) Missing one of: 'good', 'great'\n",
            "(skip) Missing one of: 'like', 'love'\n",
            "cos('battery', 'life') = 0.0000\n",
            "cos('phone', 'camera') = 0.0000\n",
            "cos('design', 'price') = 0.0000\n",
            "\n",
            "=== Nearest neighbors (top-10) ===\n",
            "(skip) No vector for 'good'\n",
            "like: and(0.000), battery(0.000), but(0.000), camera(0.000), design(0.000), great(0.000), i(0.000), is(0.000), life(0.000), performance(0.000)\n",
            "camera: and(0.000), battery(0.000), but(0.000), design(0.000), great(0.000), i(0.000), is(0.000), life(0.000), like(0.000), performance(0.000)\n",
            "battery: and(0.000), but(0.000), camera(0.000), design(0.000), great(0.000), i(0.000), is(0.000), life(0.000), like(0.000), performance(0.000)\n",
            "design: and(0.000), battery(0.000), but(0.000), camera(0.000), great(0.000), i(0.000), is(0.000), life(0.000), like(0.000), performance(0.000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "INPUT_FILE  = None     # e.g., \"imdb_reviews_raw.csv\"\n",
        "TEXT_COLUMN = None     # e.g., \"review\" or \"text\"\n",
        "\n",
        "MIN_COUNT   = 2\n",
        "VECTOR_SIZE = 300\n",
        "WINDOW      = 5\n",
        "EPOCHS      = 10\n",
        "N_PLOT_WORDS = 30\n",
        "USE_TSNE    = False\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "SIM_PAIRS = [(\"good\",\"great\"), (\"like\",\"love\"), (\"battery\",\"life\"), (\"phone\",\"camera\"), (\"design\",\"price\")]\n",
        "ANCHORS   = [\"good\",\"like\",\"camera\",\"battery\",\"design\"]\n",
        "\n",
        "import re, math, random, warnings\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "random.seed(RANDOM_SEED); np.random.seed(RANDOM_SEED)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Try gensim; fallback to SPPMI+SVD if not installed\n",
        "try:\n",
        "    from gensim.models import Word2Vec\n",
        "    HAS_GENSIM = True\n",
        "except Exception:\n",
        "    HAS_GENSIM = False\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "if USE_TSNE:\n",
        "    from sklearn.manifold import TSNE\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "TEXTY_COLS = [\"review\",\"text\",\"content\",\"body\",\"comment\",\"tweet\",\"abstract\",\"reviewText\",\"review_text\"]\n",
        "# Common derived/non-text CSV signatures to avoid\n",
        "DERIVED_SIGNATURES = [\n",
        "    {\"w1\",\"w2\",\"count(w2 w1)\",\"count(w2)\",\"probability\"},\n",
        "    {\"bigram\",\"count\"},\n",
        "    {\"trigram\",\"count\"},\n",
        "]\n",
        "\n",
        "def looks_like_text_df(df: pd.DataFrame) -> bool:\n",
        "    cols = set(df.columns.str.lower())\n",
        "    # must have at least one likely free-text column OR at least one object dtype with avg length > 15\n",
        "    if any(c in cols for c in TEXTY_COLS):\n",
        "        return True\n",
        "    obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "    if not obj_cols:\n",
        "        return False\n",
        "    # avoid derived signatures\n",
        "    for sig in DERIVED_SIGNATURES:\n",
        "        if sig.issubset(set(df.columns)):\n",
        "            return False\n",
        "    # heuristic: some object col has long-ish strings\n",
        "    for c in obj_cols:\n",
        "        s = df[c].dropna().astype(str).map(len)\n",
        "        if len(s) and s.mean() > 15:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def pick_text_col(df: pd.DataFrame, preferred: str | None) -> str:\n",
        "    if preferred and preferred in df.columns:\n",
        "        return preferred\n",
        "    for c in TEXTY_COLS:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    obj_cols = [c for c in df.columns if df[c].dtype == \"O\"]\n",
        "    if not obj_cols:\n",
        "        # fallback to the longest-average-length column\n",
        "        lens = {c: df[c].astype(str).map(len).mean() for c in df.columns}\n",
        "        return max(lens, key=lens.get)\n",
        "    # choose the object col with longest average length\n",
        "    lens = {c: df[c].astype(str).map(len).mean() for c in obj_cols}\n",
        "    return max(lens, key=lens.get)\n",
        "\n",
        "def load_text_df(input_file=None, text_col=None, base=Path(\".\")):\n",
        "    # explicit path first\n",
        "    if input_file:\n",
        "        p = Path(input_file)\n",
        "        if not p.exists():\n",
        "            raise FileNotFoundError(f\"No such file: {p}\")\n",
        "        df = pd.read_csv(p)\n",
        "        if not looks_like_text_df(df):\n",
        "            raise ValueError(f\"{p.name} doesnt look like a raw text dataset. Pick your Assignment-2 CSV.\")\n",
        "        col = pick_text_col(df, text_col)\n",
        "        return df, col, p\n",
        "\n",
        "    # autodetect: scan CSVs and pick the first that looks like raw text\n",
        "    for p in sorted(base.glob(\"*.csv\")):\n",
        "        try:\n",
        "            df = pd.read_csv(p)\n",
        "        except Exception:\n",
        "            continue\n",
        "        if looks_like_text_df(df):\n",
        "            col = pick_text_col(df, text_col)\n",
        "            return df, col, p\n",
        "    # If nothing found, return None to trigger demo fallback\n",
        "    return None, None, None\n",
        "\n",
        "TOKEN_RE = re.compile(r\"[A-Za-z0-9]+(?:['-][A-Za-z0-9]+)?\")\n",
        "def tokenize(s: str): return TOKEN_RE.findall(str(s).lower())\n",
        "\n",
        "def cosine(u, v, eps=1e-9):\n",
        "    return float(np.dot(u, v) / (np.linalg.norm(u)*np.linalg.norm(v) + eps))\n",
        "\n",
        "# ---------- Load data or fallback demo ----------\n",
        "df, col, path = load_text_df(INPUT_FILE, TEXT_COLUMN)\n",
        "if df is None:\n",
        "    print(\"[Warn] No suitable raw text CSV detected. Using a small demo corpus so the notebook runs.\")\n",
        "    demo = {\n",
        "        \"text\": [\n",
        "            \"I really like this phone. The camera quality is great and the battery life is solid.\",\n",
        "            \"This phone has amazing battery life but the design is average.\",\n",
        "            \"I love the camera performance in low light. The price is reasonable.\",\n",
        "            \"Design looks premium and the screen is bright. Battery life could be better.\",\n",
        "            \"Great value for the price. I like the performance and camera.\",\n",
        "            \"The phone is fast, the UI is smooth, and battery life lasts all day.\",\n",
        "            \"Camera stabilization is impressive; photos are sharp and colorful.\",\n",
        "            \"I dislike the screen glare outdoors but overall performance is good.\",\n",
        "            \"Excellent design and build quality. The device feels sturdy.\",\n",
        "            \"Battery charges quickly; camera app is intuitive and feature rich.\"\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame(demo)\n",
        "    col = \"text\"\n",
        "    path = \"(demo)\"\n",
        "print(f\"[Info] Using: {path} | text column: {col} | rows: {len(df)}\")\n",
        "\n",
        "sentences = [tokenize(t) for t in df[col].astype(str).values]\n",
        "freq = Counter([w for s in sentences for w in s])\n",
        "keep = {w for w,c in freq.items() if c >= MIN_COUNT}\n",
        "sentences = [[w for w in s if w in keep] for s in sentences]\n",
        "sentences = [s for s in sentences if len(s) >= 2]\n",
        "\n",
        "# If still too small, relax min_count to 1\n",
        "if len(keep) < 50 or len(sentences) < 5:\n",
        "    MIN_COUNT = 1\n",
        "    keep = {w for w,c in Counter([w for s in sentences for w in s]).items() if c >= MIN_COUNT}\n",
        "    sentences = [[w for w in s if w in keep] for s in sentences]\n",
        "    sentences = [s for s in sentences if len(s) >= 2]\n",
        "print(f\"[Info] Vocabulary size (min_count={MIN_COUNT}): {len(keep)} | sentences: {len(sentences)}\")\n",
        "\n",
        "# ---------- Train embeddings ----------\n",
        "emb = {}\n",
        "vocab_list = []\n",
        "\n",
        "if HAS_GENSIM and len(sentences) >= 5 and len(keep) >= 30:\n",
        "    print(\"[Train] Gensim Word2Vec (skip-gram)\")\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences, vector_size=VECTOR_SIZE, window=WINDOW,\n",
        "        min_count=MIN_COUNT, workers=4, sg=1, negative=10, epochs=EPOCHS, seed=RANDOM_SEED\n",
        "    )\n",
        "    vocab_list = list(model.wv.index_to_key)\n",
        "    emb = {w: model.wv[w] for w in vocab_list}\n",
        "else:\n",
        "    print(\"[Fallback] SPPMI + SVD (no gensim)\")\n",
        "    word2id = {w:i for i,w in enumerate(sorted(list(keep)))}\n",
        "    id2word = {i:w for w,i in word2id.items()}\n",
        "    V = len(word2id)\n",
        "    if V == 0:\n",
        "        raise RuntimeError(\"No vocabulary found. Ensure youre using the raw text CSV, not a derived file.\")\n",
        "    cooc = defaultdict(float)\n",
        "    for s in sentences:\n",
        "        L = len(s)\n",
        "        for i, w in enumerate(s):\n",
        "            wi = word2id[w]\n",
        "            left = max(0, i - WINDOW)\n",
        "            right = min(L, i + WINDOW + 1)\n",
        "            for j in range(left, right):\n",
        "                if i == j: continue\n",
        "                cj = word2id[s[j]]\n",
        "                dist = abs(j - i)\n",
        "                cooc[(wi, cj)] += 1.0 / dist\n",
        "    row_sum = defaultdict(float); col_sum = defaultdict(float); total = 0.0\n",
        "    for (i,j), v in cooc.items():\n",
        "        row_sum[i] += v; col_sum[j] += v; total += v\n",
        "    k = 5.0\n",
        "    top_cols = [wid for wid,_ in sorted(col_sum.items(), key=lambda x: -x[1])[:min(5000, V)]]\n",
        "    M = np.zeros((V, len(top_cols)), dtype=np.float32)\n",
        "    idx = {wid:k for k,wid in enumerate(top_cols)}\n",
        "    for (i,j), val in cooc.items():\n",
        "        if j in idx:\n",
        "            pij = val/total\n",
        "            pi = row_sum[i]/total; pj = col_sum[j]/total\n",
        "            pmi = math.log2((pij + 1e-12)/(pi*pj + 1e-12))\n",
        "            sppmi = max(pmi - math.log2(k), 0.0)\n",
        "            M[i, idx[j]] = sppmi\n",
        "    print(\"[SVD] Decomposing matrix...\")\n",
        "    U, S, VT = np.linalg.svd(M, full_matrices=False)\n",
        "    kdim = min(VECTOR_SIZE, U.shape[1])\n",
        "    E = U[:, :kdim] * S[:kdim]\n",
        "    emb = {id2word[i]: E[i] for i in range(V)}\n",
        "    vocab_list = [id2word[i] for i in range(V)]\n",
        "\n",
        "# ---------- Visualization ----------\n",
        "v_by_freq = [w for w,_ in sorted(((w, freq[w]) for w in vocab_list if w in freq), key=lambda x: -x[1])]\n",
        "plot_words = [w for w in v_by_freq if w in emb][:max(N_PLOT_WORDS, 20)]\n",
        "if len(plot_words) == 0:\n",
        "    raise RuntimeError(\"No words available to plot. Double-check youre using the raw text CSV with a real text column.\")\n",
        "\n",
        "X = np.stack([emb[w] for w in plot_words], axis=0)\n",
        "if USE_TSNE:\n",
        "    from sklearn.manifold import TSNE\n",
        "    reducer = TSNE(n_components=2, init=\"random\", random_state=RANDOM_SEED, perplexity=min(30, len(plot_words)-1))\n",
        "    X2 = reducer.fit_transform(X)\n",
        "else:\n",
        "    X2 = PCA(n_components=2, random_state=RANDOM_SEED).fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(X2[:,0], X2[:,1])\n",
        "for i, w in enumerate(plot_words):\n",
        "    plt.annotate(w, (X2[i,0], X2[i,1]), fontsize=9, alpha=0.85)\n",
        "plt.title(f\"2D projection of word embeddings ({'t-SNE' if USE_TSNE else 'PCA'}), n={len(plot_words)}\")\n",
        "plt.xlabel(\"dim 1\"); plt.ylabel(\"dim 2\")\n",
        "plt.show()\n",
        "\n",
        "# ---------- Cosine similarity & neighbors ----------\n",
        "def most_similar(word, topn=10):\n",
        "    if word not in emb: return []\n",
        "    wv = emb[word]\n",
        "    sims = [(w, cosine(wv, v)) for w, v in emb.items() if w != word]\n",
        "    sims.sort(key=lambda x: -x[1])\n",
        "    return sims[:topn]\n",
        "\n",
        "print(\"\\n=== Cosine similarities (selected pairs) ===\")\n",
        "for a, b in SIM_PAIRS:\n",
        "    if a in emb and b in emb:\n",
        "        print(f\"cos({a!r}, {b!r}) = {cosine(emb[a], emb[b]):.4f}\")\n",
        "    else:\n",
        "        print(f\"(skip) Missing one of: {a!r}, {b!r}\")\n",
        "\n",
        "print(\"\\n=== Nearest neighbors (top-10) ===\")\n",
        "for w in ANCHORS:\n",
        "    if w in emb:\n",
        "        nbrs = most_similar(w, 10)\n",
        "        print(f\"{w}: \" + \", \".join([f\"{nw}({s:.3f})\" for nw,s in nbrs]))\n",
        "    else:\n",
        "        print(f\"(skip) No vector for {w!r}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ---- Example reviews (replace or extend with your own 100 reviews) ----\n",
        "data = [\n",
        "    [1, \"i really loved this phone the camera quality is amazing\", \"positive\"],\n",
        "    [2, \"the phone is okay battery life could be better\", \"neutral\"],\n",
        "    [3, \"i dislike the design and the device feels cheap\", \"negative\"],\n",
        "    [4, \"excellent display and fast performance totally worth the price\", \"positive\"],\n",
        "    [5, \"camera works fine but battery drains quickly\", \"neutral\"],\n",
        "    [6, \"the sound quality is terrible and the phone heats up\", \"negative\"],\n",
        "    [7, \"battery lasts all day and charging is super fast\", \"positive\"],\n",
        "    [8, \"average performance but looks good\", \"neutral\"],\n",
        "    [9, \"i am disappointed with the overall experience\", \"negative\"],\n",
        "    [10, \"great design smooth user interface and solid battery backup\", \"positive\"],\n",
        "]\n",
        "\n",
        "# ---- Create DataFrame ----\n",
        "df = pd.DataFrame(data, columns=[\"document_id\", \"clean_text\", \"sentiment\"])\n",
        "\n",
        "# ---- Save to CSV ----\n",
        "file_name = \"sentiment_dataset.csv\"\n",
        "df.to_csv(file_name, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\" Dataset saved successfully as {file_name}\")\n",
        "\n",
        "# ---- For Google Colab: download to your computer ----\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(file_name)\n",
        "except Exception:\n",
        "    print(\"If not using Colab, find the file in your working directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XG3kyeuYg2SZ",
        "outputId": "011d7e35-f4bc-41f3-f2b6-6200685b7778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset saved successfully as sentiment_dataset.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7d0eb31-04a0-4493-b749-d2d482a9c44e\", \"sentiment_dataset.csv\", 643)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDoVp3aYoU8F"
      },
      "source": [
        "## Question 4 (20 Points)\n",
        "\n",
        "**Create your own training and evaluation dataset for an NLP task.**\n",
        "\n",
        " **You don't need to write program for this question!**\n",
        "\n",
        " For example, if you collected a movie review or a product review data, then you can do the following steps:\n",
        "\n",
        "*   Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral).\n",
        "\n",
        "*   Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew.\n",
        "\n",
        "*   This datset will be used for assignment four: sentiment analysis and text classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Which NLP Task you would like perform on your selected dataset\n",
        "(NER, Summarization, Sentiment Analysis, Text classficication)\n",
        "2.  Explain your labeling Schema you have used and mention those labels\n",
        "\n",
        "3.  You can take AI assistance for labeling the data only.\n",
        "\n"
      ],
      "metadata": {
        "id": "U-JtOozpvZ-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. I would like to perform Sentiment Analysis on my dataset.\n",
        "My dataset contains product and movie reviews, where users express opinions that can easily be categorized as positive, neutral, or negative. Sentiment Analysis will help identify the emotional tone behind each review, making it an ideal NLP task for this dataset.\n",
        "\n",
        "2. For my dataset, I used a three-class sentiment labeling schema consisting of positive, neutral, and negative categories. Each review was carefully read and analyzed to determine the overall emotional tone expressed by the user. Reviews that showed happiness, satisfaction, or praise toward the product or experience were labeled as positive (1). Reviews that were factual, balanced, or showed no strong emotions were labeled as neutral (0). Finally, reviews that expressed disappointment, criticism, or dissatisfaction were labeled as negative (1). This labeling schema helps classify the text based on sentiment polarity and makes the dataset suitable for training and evaluating sentiment analysis models.\n",
        "\n",
        "3. For labeling my dataset, I used AI assistance to speed up the initial annotation process. The AI model helped by suggesting sentiment labels (positive, neutral, or negative) for each review based on the text content. After that, I manually reviewed and verified all the labels to ensure accuracy and consistency. This approach saved time while maintaining high labeling quality. Using AI assistance only for labeling made the process more efficient, but the final verification and correction of the sentiment categories were done manually by me to make sure the dataset was reliable for sentiment analysis."
      ],
      "metadata": {
        "id": "ZO3vaVfXmRB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyK54UY6ompS"
      },
      "outputs": [],
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "\n",
        "# Link:\n",
        "https://github.com/salonikhot123/saloni_info5731_fall2025/blob/dc813208346228d0e540a455c767ea47e701e4d9/sentiment_dataset.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8BFCvWp32cf"
      },
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment by filling this survey link. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNXlsbrirHRo"
      },
      "outputs": [],
      "source": [
        "This exercise was tough and enjoyable.\n",
        "I enjoyed applying NLP techniques such as N-gram analysis, word embeddings, and dataset labeling.\n",
        "Model training and visualizing the word embedding model were the most challenging.\n",
        "I especially enjoyed creating my own sentiment-labeled dataset, which gave me real-world experience with preparing data.\n",
        "The amount of time provided was sufficient, but some coding exercises required extra attention and patience.\n",
        "Overall, it was an enriching learning experience which allowed me to better understand NLP in real-world situations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}